{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Search Assitant"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-14T02:33:06.966934Z",
     "start_time": "2024-09-14T02:33:05.525231Z"
    }
   },
   "source": [
    "import os\n",
    "import re\n",
    "import sys\n",
    "import yaml\n",
    "from pprint import pprint\n",
    "\n",
    "import requests\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "from serpapi import GoogleSearch\n",
    "\n",
    "from langchain.prompts import PromptTemplate, load_prompt\n",
    "from langchain.pydantic_v1 import BaseModel, Field\n",
    "from langchain_community.document_loaders import UnstructuredURLLoader\n",
    "from langchain.document_loaders import AsyncHtmlLoader\n",
    "from langchain.document_transformers import Html2TextTransformer\n",
    "from urllib.parse import urljoin, urlparse, urldefrag\n",
    "from langchain_community.llms import SambaStudio\n",
    "from langchain.embeddings import HuggingFaceInstructEmbeddings\n",
    "\n",
    "current_dir = os.getcwd()\n",
    "kit_dir = os.path.abspath(os.path.join(current_dir, '..'))\n",
    "repo_dir = os.path.abspath(os.path.join(kit_dir, '..'))\n",
    "\n",
    "sys.path.append(kit_dir)\n",
    "sys.path.append(repo_dir)\n",
    "\n",
    "from utils.model_wrappers.langchain_llms import SambaNovaCloud\n",
    "\n",
    "load_dotenv('../../.env')\n",
    "\n",
    "from langchain.globals import set_debug\n",
    "\n",
    "set_debug(False)"
   ],
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'GoogleSearch' from 'serpapi' (C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\serpapi\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mImportError\u001B[0m                               Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[1], line 10\u001B[0m\n\u001B[0;32m      8\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mjson\u001B[39;00m\n\u001B[0;32m      9\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mdotenv\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m load_dotenv\n\u001B[1;32m---> 10\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mserpapi\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m GoogleSearch\n\u001B[0;32m     12\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mlangchain\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mprompts\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m PromptTemplate, load_prompt\n\u001B[0;32m     13\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mlangchain\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpydantic_v1\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m BaseModel, Field\n",
      "\u001B[1;31mImportError\u001B[0m: cannot import name 'GoogleSearch' from 'serpapi' (C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\serpapi\\__init__.py)"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the LLM"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-14T02:33:35.484553Z",
     "start_time": "2024-09-14T02:33:35.043467Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import re\n",
    "import sys\n",
    "import yaml\n",
    "from pprint import pprint\n",
    "\n",
    "import requests\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "from serpapi import GoogleSearch\n",
    "\n",
    "from langchain.prompts import PromptTemplate, load_prompt\n",
    "from langchain.pydantic_v1 import BaseModel, Field\n",
    "from langchain_community.document_loaders import UnstructuredURLLoader\n",
    "from langchain.document_loaders import AsyncHtmlLoader\n",
    "from langchain.document_transformers import Html2TextTransformer\n",
    "from urllib.parse import urljoin, urlparse, urldefrag\n",
    "from langchain_community.llms import SambaStudio\n",
    "from langchain.embeddings import HuggingFaceInstructEmbeddings\n",
    "\n",
    "current_dir = os.getcwd()\n",
    "kit_dir = os.path.abspath(os.path.join(current_dir, '..'))\n",
    "repo_dir = os.path.abspath(os.path.join(kit_dir, '..'))\n",
    "\n",
    "sys.path.append(kit_dir)\n",
    "sys.path.append(repo_dir)\n",
    "\n",
    "from utils.model_wrappers.langchain_llms import SambaNovaCloud\n",
    "\n",
    "load_dotenv('../../.env')\n",
    "\n",
    "from langchain.globals import set_debug\n",
    "\n",
    "set_debug(False)"
   ],
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'GoogleSearch' from 'serpapi' (C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\serpapi\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mImportError\u001B[0m                               Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[2], line 10\u001B[0m\n\u001B[0;32m      8\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mjson\u001B[39;00m\n\u001B[0;32m      9\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mdotenv\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m load_dotenv\n\u001B[1;32m---> 10\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mserpapi\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m GoogleSearch\n\u001B[0;32m     12\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mlangchain\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mprompts\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m PromptTemplate, load_prompt\n\u001B[0;32m     13\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mlangchain\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpydantic_v1\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m BaseModel, Field\n",
      "\u001B[1;31mImportError\u001B[0m: cannot import name 'GoogleSearch' from 'serpapi' (C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\serpapi\\__init__.py)"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-14T02:34:42.441628Z",
     "start_time": "2024-09-14T02:34:42.396147Z"
    }
   },
   "source": [
    "# Sambastudio LLM\n",
    "#llm = SambaStudio(\n",
    "#    streaming=True,\n",
    "#    model_kwargs={\n",
    "#     'max_tokens_to_generate': 500,\n",
    "#     'temperature': 0.01,\n",
    "#     'top_p': 1,\n",
    "#     'process_prompt': False,\n",
    "#     'select_expert': 'Meta-Llama-3-8B-Instruct'\n",
    "# },\n",
    "# )\n",
    "\n",
    "#sncloud llm\n",
    "llm = SambaNovaCloud(\n",
    "    max_tokens = 500,\n",
    "    model= 'llama3-8b',\n",
    ")"
   ],
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'SambaNovaCloud' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[3], line 14\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;66;03m# Sambastudio LLM\u001B[39;00m\n\u001B[0;32m      2\u001B[0m \u001B[38;5;66;03m#llm = SambaStudio(\u001B[39;00m\n\u001B[0;32m      3\u001B[0m \u001B[38;5;66;03m#    streaming=True,\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m     12\u001B[0m \n\u001B[0;32m     13\u001B[0m \u001B[38;5;66;03m#sncloud llm\u001B[39;00m\n\u001B[1;32m---> 14\u001B[0m llm \u001B[38;5;241m=\u001B[39m \u001B[43mSambaNovaCloud\u001B[49m(\n\u001B[0;32m     15\u001B[0m     max_tokens \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m500\u001B[39m,\n\u001B[0;32m     16\u001B[0m     model\u001B[38;5;241m=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mllama3-70b\u001B[39m\u001B[38;5;124m'\u001B[39m,\n\u001B[0;32m     17\u001B[0m )\n",
      "\u001B[1;31mNameError\u001B[0m: name 'SambaNovaCloud' is not defined"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search tools"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-14T02:34:46.728609Z",
     "start_time": "2024-09-14T02:34:46.712986Z"
    }
   },
   "source": [
    "# Only admits Google Search\n",
    "def querySerper(query: str, limit: int = 5, do_analysis: bool = True, include_site_links: bool = False):\n",
    "    \"\"\"A search engine. Useful for when you need to answer questions about current events. Input should be a search query.\"\"\"\n",
    "    url = 'https://google.serper.dev/search'\n",
    "    payload = json.dumps({'q': query, 'num': limit})\n",
    "    headers = {'X-API-KEY': os.environ.get('SERPER_API_KEY'), 'Content-Type': 'application/json'}\n",
    "\n",
    "    response = requests.post(url, headers=headers, data=payload).json()\n",
    "    results = response['organic']\n",
    "    links = [r['link'] for r in results]\n",
    "    if include_site_links:\n",
    "        sitelinks = []\n",
    "        for r in [r.get('sitelinks', []) for r in results]:\n",
    "            sitelinks.extend([site.get('link', None) for site in r])\n",
    "        links.extend(sitelinks)\n",
    "    links = list(filter(lambda x: x is not None, links))\n",
    "\n",
    "    if do_analysis:\n",
    "        prompt = load_prompt(os.path.join(kit_dir, 'prompts/llama3-serp_analysis.yaml'))\n",
    "        formatted_prompt = prompt.format(question=query, context=json.dumps(results))\n",
    "        return llm.invoke(formatted_prompt), links\n",
    "    else:\n",
    "        return response, links"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-14T02:34:51.575346Z",
     "start_time": "2024-09-14T02:34:50.694905Z"
    }
   },
   "source": [
    "querySerper('who is the president of America', do_analysis=True)"
   ],
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'organic'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[5], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[43mquerySerper\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mwho is the president of America\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdo_analysis\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[1;32mIn[4], line 9\u001B[0m, in \u001B[0;36mquerySerper\u001B[1;34m(query, limit, do_analysis, include_site_links)\u001B[0m\n\u001B[0;32m      6\u001B[0m headers \u001B[38;5;241m=\u001B[39m {\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mX-API-KEY\u001B[39m\u001B[38;5;124m'\u001B[39m: os\u001B[38;5;241m.\u001B[39menviron\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mSERPER_API_KEY\u001B[39m\u001B[38;5;124m'\u001B[39m), \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mContent-Type\u001B[39m\u001B[38;5;124m'\u001B[39m: \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mapplication/json\u001B[39m\u001B[38;5;124m'\u001B[39m}\n\u001B[0;32m      8\u001B[0m response \u001B[38;5;241m=\u001B[39m requests\u001B[38;5;241m.\u001B[39mpost(url, headers\u001B[38;5;241m=\u001B[39mheaders, data\u001B[38;5;241m=\u001B[39mpayload)\u001B[38;5;241m.\u001B[39mjson()\n\u001B[1;32m----> 9\u001B[0m results \u001B[38;5;241m=\u001B[39m \u001B[43mresponse\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43morganic\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\n\u001B[0;32m     10\u001B[0m links \u001B[38;5;241m=\u001B[39m [r[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mlink\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;28;01mfor\u001B[39;00m r \u001B[38;5;129;01min\u001B[39;00m results]\n\u001B[0;32m     11\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m include_site_links:\n",
      "\u001B[1;31mKeyError\u001B[0m: 'organic'"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-14T02:35:06.489405Z",
     "start_time": "2024-09-14T02:35:06.477087Z"
    }
   },
   "source": [
    "def queryOpenSerp(query: str, limit: int = 5, do_analysis: bool = True, engine='google') -> str:\n",
    "    \"\"\"A search engine. Useful for when you need to answer questions about current events. Input should be a search query.\"\"\"\n",
    "    if engine not in ['google', 'yandex', 'baidu']:\n",
    "        raise ValueError('engine must be either google, yandex or baidu')\n",
    "    url = f'http://127.0.0.1:7000/{engine}/search'\n",
    "    params = {'lang': 'EN', 'limit': limit, 'text': query}\n",
    "\n",
    "    results = requests.get(url, params=params).json()\n",
    "\n",
    "    links = [r['url'] for r in results]\n",
    "    if do_analysis:\n",
    "        prompt = load_prompt(os.path.join(kit_dir, 'prompts/llama3-serp_analysis.yaml'))\n",
    "        formatted_prompt = prompt.format(question=query, context=json.dumps(results))\n",
    "        return llm.invoke(formatted_prompt), links\n",
    "    else:\n",
    "        return results, links"
   ],
   "outputs": [],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-14T02:35:18.941492Z",
     "start_time": "2024-09-14T02:35:13.227007Z"
    }
   },
   "source": [
    "queryOpenSerp('who is the president of America', do_analysis=True, engine='google')"
   ],
   "outputs": [
    {
     "ename": "ConnectionError",
     "evalue": "HTTPConnectionPool(host='127.0.0.1', port=7000): Max retries exceeded with url: /google/search?lang=EN&limit=5&text=who+is+the+president+of+America (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000021E1C5AA910>: Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it'))",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mConnectionRefusedError\u001B[0m                    Traceback (most recent call last)",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\urllib3\\connection.py:196\u001B[0m, in \u001B[0;36mHTTPConnection._new_conn\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    195\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 196\u001B[0m     sock \u001B[38;5;241m=\u001B[39m \u001B[43mconnection\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcreate_connection\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    197\u001B[0m \u001B[43m        \u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_dns_host\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mport\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    198\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtimeout\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    199\u001B[0m \u001B[43m        \u001B[49m\u001B[43msource_address\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msource_address\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    200\u001B[0m \u001B[43m        \u001B[49m\u001B[43msocket_options\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msocket_options\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    201\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    202\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m socket\u001B[38;5;241m.\u001B[39mgaierror \u001B[38;5;28;01mas\u001B[39;00m e:\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\urllib3\\util\\connection.py:85\u001B[0m, in \u001B[0;36mcreate_connection\u001B[1;34m(address, timeout, source_address, socket_options)\u001B[0m\n\u001B[0;32m     84\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m---> 85\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m err\n\u001B[0;32m     86\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[0;32m     87\u001B[0m     \u001B[38;5;66;03m# Break explicitly a reference cycle\u001B[39;00m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\urllib3\\util\\connection.py:73\u001B[0m, in \u001B[0;36mcreate_connection\u001B[1;34m(address, timeout, source_address, socket_options)\u001B[0m\n\u001B[0;32m     72\u001B[0m     sock\u001B[38;5;241m.\u001B[39mbind(source_address)\n\u001B[1;32m---> 73\u001B[0m \u001B[43msock\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconnect\u001B[49m\u001B[43m(\u001B[49m\u001B[43msa\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     74\u001B[0m \u001B[38;5;66;03m# Break explicitly a reference cycle\u001B[39;00m\n",
      "\u001B[1;31mConnectionRefusedError\u001B[0m: [WinError 10061] No connection could be made because the target machine actively refused it",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001B[1;31mNewConnectionError\u001B[0m                        Traceback (most recent call last)",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\urllib3\\connectionpool.py:789\u001B[0m, in \u001B[0;36mHTTPConnectionPool.urlopen\u001B[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001B[0m\n\u001B[0;32m    788\u001B[0m \u001B[38;5;66;03m# Make the request on the HTTPConnection object\u001B[39;00m\n\u001B[1;32m--> 789\u001B[0m response \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_make_request\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    790\u001B[0m \u001B[43m    \u001B[49m\u001B[43mconn\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    791\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmethod\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    792\u001B[0m \u001B[43m    \u001B[49m\u001B[43murl\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    793\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtimeout_obj\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    794\u001B[0m \u001B[43m    \u001B[49m\u001B[43mbody\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbody\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    795\u001B[0m \u001B[43m    \u001B[49m\u001B[43mheaders\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mheaders\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    796\u001B[0m \u001B[43m    \u001B[49m\u001B[43mchunked\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mchunked\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    797\u001B[0m \u001B[43m    \u001B[49m\u001B[43mretries\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mretries\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    798\u001B[0m \u001B[43m    \u001B[49m\u001B[43mresponse_conn\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mresponse_conn\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    799\u001B[0m \u001B[43m    \u001B[49m\u001B[43mpreload_content\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpreload_content\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    800\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdecode_content\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdecode_content\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    801\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mresponse_kw\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    802\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    804\u001B[0m \u001B[38;5;66;03m# Everything went great!\u001B[39;00m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\urllib3\\connectionpool.py:495\u001B[0m, in \u001B[0;36mHTTPConnectionPool._make_request\u001B[1;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001B[0m\n\u001B[0;32m    494\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 495\u001B[0m     \u001B[43mconn\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrequest\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    496\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmethod\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    497\u001B[0m \u001B[43m        \u001B[49m\u001B[43murl\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    498\u001B[0m \u001B[43m        \u001B[49m\u001B[43mbody\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbody\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    499\u001B[0m \u001B[43m        \u001B[49m\u001B[43mheaders\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mheaders\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    500\u001B[0m \u001B[43m        \u001B[49m\u001B[43mchunked\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mchunked\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    501\u001B[0m \u001B[43m        \u001B[49m\u001B[43mpreload_content\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpreload_content\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    502\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdecode_content\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdecode_content\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    503\u001B[0m \u001B[43m        \u001B[49m\u001B[43menforce_content_length\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43menforce_content_length\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    504\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    506\u001B[0m \u001B[38;5;66;03m# We are swallowing BrokenPipeError (errno.EPIPE) since the server is\u001B[39;00m\n\u001B[0;32m    507\u001B[0m \u001B[38;5;66;03m# legitimately able to close the connection after sending a valid response.\u001B[39;00m\n\u001B[0;32m    508\u001B[0m \u001B[38;5;66;03m# With this behaviour, the received response is still readable.\u001B[39;00m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\urllib3\\connection.py:398\u001B[0m, in \u001B[0;36mHTTPConnection.request\u001B[1;34m(self, method, url, body, headers, chunked, preload_content, decode_content, enforce_content_length)\u001B[0m\n\u001B[0;32m    397\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mputheader(header, value)\n\u001B[1;32m--> 398\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mendheaders\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    400\u001B[0m \u001B[38;5;66;03m# If we're given a body we start sending that in chunks.\u001B[39;00m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\http\\client.py:1277\u001B[0m, in \u001B[0;36mHTTPConnection.endheaders\u001B[1;34m(self, message_body, encode_chunked)\u001B[0m\n\u001B[0;32m   1276\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m CannotSendHeader()\n\u001B[1;32m-> 1277\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_send_output\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmessage_body\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mencode_chunked\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mencode_chunked\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\http\\client.py:1037\u001B[0m, in \u001B[0;36mHTTPConnection._send_output\u001B[1;34m(self, message_body, encode_chunked)\u001B[0m\n\u001B[0;32m   1036\u001B[0m \u001B[38;5;28;01mdel\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_buffer[:]\n\u001B[1;32m-> 1037\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msend\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmsg\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1039\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m message_body \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m   1040\u001B[0m \n\u001B[0;32m   1041\u001B[0m     \u001B[38;5;66;03m# create a consistent interface to message_body\u001B[39;00m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\http\\client.py:975\u001B[0m, in \u001B[0;36mHTTPConnection.send\u001B[1;34m(self, data)\u001B[0m\n\u001B[0;32m    974\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mauto_open:\n\u001B[1;32m--> 975\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconnect\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    976\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\urllib3\\connection.py:236\u001B[0m, in \u001B[0;36mHTTPConnection.connect\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    235\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mconnect\u001B[39m(\u001B[38;5;28mself\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m--> 236\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msock \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_new_conn\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    237\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_tunnel_host:\n\u001B[0;32m    238\u001B[0m         \u001B[38;5;66;03m# If we're tunneling it means we're connected to our proxy.\u001B[39;00m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\urllib3\\connection.py:211\u001B[0m, in \u001B[0;36mHTTPConnection._new_conn\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    210\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mOSError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m--> 211\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m NewConnectionError(\n\u001B[0;32m    212\u001B[0m         \u001B[38;5;28mself\u001B[39m, \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mFailed to establish a new connection: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00me\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    213\u001B[0m     ) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01me\u001B[39;00m\n\u001B[0;32m    215\u001B[0m \u001B[38;5;66;03m# Audit hooks are only available in Python 3.8+\u001B[39;00m\n",
      "\u001B[1;31mNewConnectionError\u001B[0m: <urllib3.connection.HTTPConnection object at 0x0000021E1C5AA910>: Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001B[1;31mMaxRetryError\u001B[0m                             Traceback (most recent call last)",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\requests\\adapters.py:667\u001B[0m, in \u001B[0;36mHTTPAdapter.send\u001B[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001B[0m\n\u001B[0;32m    666\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 667\u001B[0m     resp \u001B[38;5;241m=\u001B[39m \u001B[43mconn\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43murlopen\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    668\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmethod\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrequest\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmethod\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    669\u001B[0m \u001B[43m        \u001B[49m\u001B[43murl\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43murl\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    670\u001B[0m \u001B[43m        \u001B[49m\u001B[43mbody\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrequest\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbody\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    671\u001B[0m \u001B[43m        \u001B[49m\u001B[43mheaders\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrequest\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mheaders\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    672\u001B[0m \u001B[43m        \u001B[49m\u001B[43mredirect\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m    673\u001B[0m \u001B[43m        \u001B[49m\u001B[43massert_same_host\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m    674\u001B[0m \u001B[43m        \u001B[49m\u001B[43mpreload_content\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m    675\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdecode_content\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m    676\u001B[0m \u001B[43m        \u001B[49m\u001B[43mretries\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmax_retries\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    677\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtimeout\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    678\u001B[0m \u001B[43m        \u001B[49m\u001B[43mchunked\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mchunked\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    679\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    681\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m (ProtocolError, \u001B[38;5;167;01mOSError\u001B[39;00m) \u001B[38;5;28;01mas\u001B[39;00m err:\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\urllib3\\connectionpool.py:843\u001B[0m, in \u001B[0;36mHTTPConnectionPool.urlopen\u001B[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001B[0m\n\u001B[0;32m    841\u001B[0m     new_e \u001B[38;5;241m=\u001B[39m ProtocolError(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mConnection aborted.\u001B[39m\u001B[38;5;124m\"\u001B[39m, new_e)\n\u001B[1;32m--> 843\u001B[0m retries \u001B[38;5;241m=\u001B[39m \u001B[43mretries\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mincrement\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    844\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmethod\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43murl\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43merror\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mnew_e\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m_pool\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m_stacktrace\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msys\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mexc_info\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m2\u001B[39;49m\u001B[43m]\u001B[49m\n\u001B[0;32m    845\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    846\u001B[0m retries\u001B[38;5;241m.\u001B[39msleep()\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\urllib3\\util\\retry.py:519\u001B[0m, in \u001B[0;36mRetry.increment\u001B[1;34m(self, method, url, response, error, _pool, _stacktrace)\u001B[0m\n\u001B[0;32m    518\u001B[0m     reason \u001B[38;5;241m=\u001B[39m error \u001B[38;5;129;01mor\u001B[39;00m ResponseError(cause)\n\u001B[1;32m--> 519\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m MaxRetryError(_pool, url, reason) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mreason\u001B[39;00m  \u001B[38;5;66;03m# type: ignore[arg-type]\u001B[39;00m\n\u001B[0;32m    521\u001B[0m log\u001B[38;5;241m.\u001B[39mdebug(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mIncremented Retry for (url=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m): \u001B[39m\u001B[38;5;132;01m%r\u001B[39;00m\u001B[38;5;124m\"\u001B[39m, url, new_retry)\n",
      "\u001B[1;31mMaxRetryError\u001B[0m: HTTPConnectionPool(host='127.0.0.1', port=7000): Max retries exceeded with url: /google/search?lang=EN&limit=5&text=who+is+the+president+of+America (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000021E1C5AA910>: Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it'))",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[1;31mConnectionError\u001B[0m                           Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[7], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[43mqueryOpenSerp\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mwho is the president of America\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdo_analysis\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mengine\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mgoogle\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[1;32mIn[6], line 8\u001B[0m, in \u001B[0;36mqueryOpenSerp\u001B[1;34m(query, limit, do_analysis, engine)\u001B[0m\n\u001B[0;32m      5\u001B[0m url \u001B[38;5;241m=\u001B[39m \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mhttp://127.0.0.1:7000/\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mengine\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m/search\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[0;32m      6\u001B[0m params \u001B[38;5;241m=\u001B[39m {\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mlang\u001B[39m\u001B[38;5;124m'\u001B[39m: \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mEN\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mlimit\u001B[39m\u001B[38;5;124m'\u001B[39m: limit, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtext\u001B[39m\u001B[38;5;124m'\u001B[39m: query}\n\u001B[1;32m----> 8\u001B[0m results \u001B[38;5;241m=\u001B[39m \u001B[43mrequests\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[43murl\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mparams\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mparams\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39mjson()\n\u001B[0;32m     10\u001B[0m links \u001B[38;5;241m=\u001B[39m [r[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124murl\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;28;01mfor\u001B[39;00m r \u001B[38;5;129;01min\u001B[39;00m results]\n\u001B[0;32m     11\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m do_analysis:\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\requests\\api.py:73\u001B[0m, in \u001B[0;36mget\u001B[1;34m(url, params, **kwargs)\u001B[0m\n\u001B[0;32m     62\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mget\u001B[39m(url, params\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[0;32m     63\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124mr\u001B[39m\u001B[38;5;124;03m\"\"\"Sends a GET request.\u001B[39;00m\n\u001B[0;32m     64\u001B[0m \n\u001B[0;32m     65\u001B[0m \u001B[38;5;124;03m    :param url: URL for the new :class:`Request` object.\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m     70\u001B[0m \u001B[38;5;124;03m    :rtype: requests.Response\u001B[39;00m\n\u001B[0;32m     71\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m---> 73\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mrequest\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mget\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43murl\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mparams\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mparams\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\requests\\api.py:59\u001B[0m, in \u001B[0;36mrequest\u001B[1;34m(method, url, **kwargs)\u001B[0m\n\u001B[0;32m     55\u001B[0m \u001B[38;5;66;03m# By using the 'with' statement we are sure the session is closed, thus we\u001B[39;00m\n\u001B[0;32m     56\u001B[0m \u001B[38;5;66;03m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001B[39;00m\n\u001B[0;32m     57\u001B[0m \u001B[38;5;66;03m# cases, and look like a memory leak in others.\u001B[39;00m\n\u001B[0;32m     58\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m sessions\u001B[38;5;241m.\u001B[39mSession() \u001B[38;5;28;01mas\u001B[39;00m session:\n\u001B[1;32m---> 59\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43msession\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrequest\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmethod\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmethod\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43murl\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43murl\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\requests\\sessions.py:589\u001B[0m, in \u001B[0;36mSession.request\u001B[1;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001B[0m\n\u001B[0;32m    584\u001B[0m send_kwargs \u001B[38;5;241m=\u001B[39m {\n\u001B[0;32m    585\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtimeout\u001B[39m\u001B[38;5;124m\"\u001B[39m: timeout,\n\u001B[0;32m    586\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mallow_redirects\u001B[39m\u001B[38;5;124m\"\u001B[39m: allow_redirects,\n\u001B[0;32m    587\u001B[0m }\n\u001B[0;32m    588\u001B[0m send_kwargs\u001B[38;5;241m.\u001B[39mupdate(settings)\n\u001B[1;32m--> 589\u001B[0m resp \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msend\u001B[49m\u001B[43m(\u001B[49m\u001B[43mprep\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43msend_kwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    591\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m resp\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\requests\\sessions.py:703\u001B[0m, in \u001B[0;36mSession.send\u001B[1;34m(self, request, **kwargs)\u001B[0m\n\u001B[0;32m    700\u001B[0m start \u001B[38;5;241m=\u001B[39m preferred_clock()\n\u001B[0;32m    702\u001B[0m \u001B[38;5;66;03m# Send the request\u001B[39;00m\n\u001B[1;32m--> 703\u001B[0m r \u001B[38;5;241m=\u001B[39m \u001B[43madapter\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msend\u001B[49m\u001B[43m(\u001B[49m\u001B[43mrequest\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    705\u001B[0m \u001B[38;5;66;03m# Total elapsed time of the request (approximately)\u001B[39;00m\n\u001B[0;32m    706\u001B[0m elapsed \u001B[38;5;241m=\u001B[39m preferred_clock() \u001B[38;5;241m-\u001B[39m start\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\requests\\adapters.py:700\u001B[0m, in \u001B[0;36mHTTPAdapter.send\u001B[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001B[0m\n\u001B[0;32m    696\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(e\u001B[38;5;241m.\u001B[39mreason, _SSLError):\n\u001B[0;32m    697\u001B[0m         \u001B[38;5;66;03m# This branch is for urllib3 v1.22 and later.\u001B[39;00m\n\u001B[0;32m    698\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m SSLError(e, request\u001B[38;5;241m=\u001B[39mrequest)\n\u001B[1;32m--> 700\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mConnectionError\u001B[39;00m(e, request\u001B[38;5;241m=\u001B[39mrequest)\n\u001B[0;32m    702\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m ClosedPoolError \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m    703\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mConnectionError\u001B[39;00m(e, request\u001B[38;5;241m=\u001B[39mrequest)\n",
      "\u001B[1;31mConnectionError\u001B[0m: HTTPConnectionPool(host='127.0.0.1', port=7000): Max retries exceeded with url: /google/search?lang=EN&limit=5&text=who+is+the+president+of+America (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000021E1C5AA910>: Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it'))"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-14T02:35:20.589523Z",
     "start_time": "2024-09-14T02:35:20.569125Z"
    }
   },
   "source": [
    "def remove_links(text):\n",
    "    url_pattern = r'https?://\\S+|www\\.\\S+'\n",
    "    return re.sub(url_pattern, '', text)\n",
    "\n",
    "\n",
    "def querySerpapi(query: str, limit: int = 5, do_analysis: bool = True, engine='google') -> str:\n",
    "    if engine not in ['google', 'bing']:\n",
    "        raise ValueError('engine must be either google or bing')\n",
    "    params = {'q': query, 'num': limit, 'engine': engine, 'api_key': os.environ.get('SERPAPI_API_KEY')}\n",
    "\n",
    "    search = GoogleSearch(params)\n",
    "    response = search.get_dict()\n",
    "\n",
    "    knowledge_graph = response.get('knowledge_graph', None)\n",
    "    results = response.get('organic_results', None)\n",
    "\n",
    "    links = []\n",
    "    links = [r['link'] for r in results]\n",
    "\n",
    "    if do_analysis:\n",
    "        prompt = load_prompt(os.path.join(kit_dir, 'prompts/llama3-serp_analysis.yaml'))\n",
    "        if knowledge_graph:\n",
    "            knowledge_graph_str = json.dumps(knowledge_graph)\n",
    "            knowledge_graph = remove_links(knowledge_graph_str)\n",
    "            print(knowledge_graph)\n",
    "            formatted_prompt = prompt.format(question=query, context=json.dumps(knowledge_graph))\n",
    "        else:\n",
    "            results_str = json.dumps(results)\n",
    "            results_str = remove_links(results_str)\n",
    "            formatted_prompt = prompt.format(question=query, context=json.dumps(results))\n",
    "        return llm.invoke(formatted_prompt), links\n",
    "    else:\n",
    "        return response, links"
   ],
   "outputs": [],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-14T02:35:22.940160Z",
     "start_time": "2024-09-14T02:35:22.842713Z"
    }
   },
   "source": [
    "pprint(querySerpapi('Who is the president of USA', engine='bing'))"
   ],
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'GoogleSearch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[9], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m pprint(\u001B[43mquerySerpapi\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mWho is the president of USA\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mengine\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mbing\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m)\n",
      "Cell \u001B[1;32mIn[8], line 11\u001B[0m, in \u001B[0;36mquerySerpapi\u001B[1;34m(query, limit, do_analysis, engine)\u001B[0m\n\u001B[0;32m      8\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mengine must be either google or bing\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m      9\u001B[0m params \u001B[38;5;241m=\u001B[39m {\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mq\u001B[39m\u001B[38;5;124m'\u001B[39m: query, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mnum\u001B[39m\u001B[38;5;124m'\u001B[39m: limit, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mengine\u001B[39m\u001B[38;5;124m'\u001B[39m: engine, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mapi_key\u001B[39m\u001B[38;5;124m'\u001B[39m: os\u001B[38;5;241m.\u001B[39menviron\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mSERPAPI_API_KEY\u001B[39m\u001B[38;5;124m'\u001B[39m)}\n\u001B[1;32m---> 11\u001B[0m search \u001B[38;5;241m=\u001B[39m \u001B[43mGoogleSearch\u001B[49m(params)\n\u001B[0;32m     12\u001B[0m response \u001B[38;5;241m=\u001B[39m search\u001B[38;5;241m.\u001B[39mget_dict()\n\u001B[0;32m     14\u001B[0m knowledge_graph \u001B[38;5;241m=\u001B[39m response\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mknowledge_graph\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m)\n",
      "\u001B[1;31mNameError\u001B[0m: name 'GoogleSearch' is not defined"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-14T02:35:24.172480Z",
     "start_time": "2024-09-14T02:35:24.082460Z"
    }
   },
   "source": [
    "pprint(querySerpapi('Who is the president of USA', engine='google'))"
   ],
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'GoogleSearch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[10], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m pprint(\u001B[43mquerySerpapi\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mWho is the president of USA\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mengine\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mgoogle\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m)\n",
      "Cell \u001B[1;32mIn[8], line 11\u001B[0m, in \u001B[0;36mquerySerpapi\u001B[1;34m(query, limit, do_analysis, engine)\u001B[0m\n\u001B[0;32m      8\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mengine must be either google or bing\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m      9\u001B[0m params \u001B[38;5;241m=\u001B[39m {\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mq\u001B[39m\u001B[38;5;124m'\u001B[39m: query, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mnum\u001B[39m\u001B[38;5;124m'\u001B[39m: limit, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mengine\u001B[39m\u001B[38;5;124m'\u001B[39m: engine, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mapi_key\u001B[39m\u001B[38;5;124m'\u001B[39m: os\u001B[38;5;241m.\u001B[39menviron\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mSERPAPI_API_KEY\u001B[39m\u001B[38;5;124m'\u001B[39m)}\n\u001B[1;32m---> 11\u001B[0m search \u001B[38;5;241m=\u001B[39m \u001B[43mGoogleSearch\u001B[49m(params)\n\u001B[0;32m     12\u001B[0m response \u001B[38;5;241m=\u001B[39m search\u001B[38;5;241m.\u001B[39mget_dict()\n\u001B[0;32m     14\u001B[0m knowledge_graph \u001B[38;5;241m=\u001B[39m response\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mknowledge_graph\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m)\n",
      "\u001B[1;31mNameError\u001B[0m: name 'GoogleSearch' is not defined"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web scrapping methods"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-14T02:35:26.899993Z",
     "start_time": "2024-09-14T02:35:26.844749Z"
    }
   },
   "source": [
    "CONFIG_PATH = os.path.join(kit_dir, 'config.yaml')"
   ],
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'kit_dir' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[11], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m CONFIG_PATH \u001B[38;5;241m=\u001B[39m os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mjoin(\u001B[43mkit_dir\u001B[49m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mconfig.yaml\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
      "\u001B[1;31mNameError\u001B[0m: name 'kit_dir' is not defined"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-14T02:35:27.890486Z",
     "start_time": "2024-09-14T02:35:27.881100Z"
    }
   },
   "source": [
    "def get_config_info():\n",
    "    \"\"\"\n",
    "    Loads json config file\n",
    "    \"\"\"\n",
    "    # Read config file\n",
    "    with open(CONFIG_PATH, 'r') as yaml_file:\n",
    "        config = yaml.safe_load(yaml_file)\n",
    "    api_info = config['api']\n",
    "    llm_info = config['llm']\n",
    "    retrieval_info = config['retrieval']\n",
    "    web_crawling_params = config['web_crawling']\n",
    "    extra_loaders = config['extra_loaders']\n",
    "\n",
    "    return api_info, llm_info, retrieval_info, web_crawling_params, extra_loaders"
   ],
   "outputs": [],
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-14T02:35:29.645233Z",
     "start_time": "2024-09-14T02:35:29.637806Z"
    }
   },
   "source": [
    "def load_remote_pdf(url):\n",
    "    \"\"\"\n",
    "    Load PDF files from the given URL.\n",
    "    Args:\n",
    "        url (str): URL to load pdf document from.\n",
    "    Returns:\n",
    "        list: A list of loaded pdf documents.\n",
    "    \"\"\"\n",
    "    loader = UnstructuredURLLoader(urls=[url])\n",
    "    docs = loader.load()\n",
    "    return docs"
   ],
   "outputs": [],
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-14T02:35:30.588435Z",
     "start_time": "2024-09-14T02:35:30.579225Z"
    }
   },
   "source": [
    "def load_htmls(urls, extra_loaders=None):\n",
    "    \"\"\"\n",
    "    Load HTML documents from the given URLs.\n",
    "    Args:\n",
    "        urls (list): A list of URLs to load HTML documents from.\n",
    "    Returns:\n",
    "        list: A list of loaded HTML documents.\n",
    "    \"\"\"\n",
    "    if extra_loaders is None:\n",
    "        extra_loaders = []\n",
    "    docs = []\n",
    "    for url in urls:\n",
    "        if url.endswith('.pdf'):\n",
    "            if 'pdf' in extra_loaders:\n",
    "                docs.extend(load_remote_pdf(url))\n",
    "            else:\n",
    "                continue\n",
    "        else:\n",
    "            loader = AsyncHtmlLoader(url, verify_ssl=False)\n",
    "            docs.extend(loader.load())\n",
    "    return docs"
   ],
   "outputs": [],
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-14T02:35:31.203822Z",
     "start_time": "2024-09-14T02:35:31.196078Z"
    }
   },
   "source": [
    "def link_filter(all_links, excluded_links):\n",
    "    \"\"\"\n",
    "    Filters a list of links based on a list of excluded links.\n",
    "    Args:\n",
    "        all_links (List[str]): A list of links to filter.\n",
    "        excluded_links (List[str]): A list of excluded links.\n",
    "    Returns:\n",
    "        Set[str]: A list of filtered links.\n",
    "    \"\"\"\n",
    "    clean_excluded_links = set()\n",
    "    for excluded_link in excluded_links:\n",
    "        parsed_link = urlparse(excluded_link)\n",
    "        clean_excluded_links.add(parsed_link.netloc + parsed_link.path)\n",
    "    filtered_links = set()\n",
    "    for link in all_links:\n",
    "        # Check if the link contains any of the excluded links\n",
    "        if not any(excluded_link in link for excluded_link in clean_excluded_links):\n",
    "            filtered_links.add(link)\n",
    "    return filtered_links"
   ],
   "outputs": [],
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-14T02:35:31.802994Z",
     "start_time": "2024-09-14T02:35:31.795993Z"
    }
   },
   "source": [
    "def clean_docs(docs):\n",
    "    \"\"\"\n",
    "    Clean the given HTML documents by transforming them into plain text.\n",
    "    Args:\n",
    "        docs (list): A list of langchain documents with html content to clean.\n",
    "    Returns:\n",
    "        list: A list of cleaned plain text documents.\n",
    "    \"\"\"\n",
    "    html2text_transformer = Html2TextTransformer()\n",
    "    docs = html2text_transformer.transform_documents(documents=docs)\n",
    "    return docs"
   ],
   "outputs": [],
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-14T02:35:32.423251Z",
     "start_time": "2024-09-14T02:35:32.379488Z"
    }
   },
   "source": [
    "def web_crawl(urls, excluded_links=None):\n",
    "    \"\"\"\n",
    "    Perform web crawling, retrieve and clean HTML documents from the given URLs, with specified depth of exploration.\n",
    "    Args:\n",
    "        urls (list): A list of URLs to crawl.\n",
    "        excluded_links (list, optional): A list of links to exclude from crawling. Defaults to None.\n",
    "        depth (int, optional): The depth of crawling, determining how many layers of internal links to explore. Defaults to 1\n",
    "    Returns:\n",
    "        tuple: A tuple containing the langchain documents (list) and the scrapped URLs (list).\n",
    "    \"\"\"\n",
    "    *_, web_crawling_params, extra_loaders = get_config_info()\n",
    "    if excluded_links is None:\n",
    "        excluded_links = []\n",
    "    excluded_links.extend(\n",
    "        [\n",
    "            'facebook.com',\n",
    "            'twitter.com',\n",
    "            'instagram.com',\n",
    "            'linkedin.com',\n",
    "            'telagram.me',\n",
    "            'reddit.com',\n",
    "            'whatsapp.com',\n",
    "            'wa.me',\n",
    "        ]\n",
    "    )\n",
    "    excluded_link_suffixes = {'.ico', '.svg', '.jpg', '.png', '.jpeg', '.', '.docx', '.xls', '.xlsx'}\n",
    "    scrapped_urls = []\n",
    "\n",
    "    urls = [url for url in urls if not url.endswith(tuple(excluded_link_suffixes))]\n",
    "    urls = link_filter(urls, set(excluded_links))\n",
    "    urls = list(urls)[: web_crawling_params['max_scraped_websites']]\n",
    "\n",
    "    scraped_docs = load_htmls(urls, extra_loaders)\n",
    "    scrapped_urls.append(urls)\n",
    "\n",
    "    docs = clean_docs(scraped_docs)\n",
    "    return docs, scrapped_urls"
   ],
   "outputs": [],
   "execution_count": 17
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-14T02:35:32.988900Z",
     "start_time": "2024-09-14T02:35:32.927670Z"
    }
   },
   "source": [
    "_, links = querySerpapi('Who is the president of USA', engine='google', do_analysis=False)\n",
    "docs, links = web_crawl(links)"
   ],
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'GoogleSearch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[18], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m _, links \u001B[38;5;241m=\u001B[39m \u001B[43mquerySerpapi\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mWho is the president of USA\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mengine\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mgoogle\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdo_analysis\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[0;32m      2\u001B[0m docs, links \u001B[38;5;241m=\u001B[39m web_crawl(links)\n",
      "Cell \u001B[1;32mIn[8], line 11\u001B[0m, in \u001B[0;36mquerySerpapi\u001B[1;34m(query, limit, do_analysis, engine)\u001B[0m\n\u001B[0;32m      8\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mengine must be either google or bing\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m      9\u001B[0m params \u001B[38;5;241m=\u001B[39m {\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mq\u001B[39m\u001B[38;5;124m'\u001B[39m: query, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mnum\u001B[39m\u001B[38;5;124m'\u001B[39m: limit, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mengine\u001B[39m\u001B[38;5;124m'\u001B[39m: engine, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mapi_key\u001B[39m\u001B[38;5;124m'\u001B[39m: os\u001B[38;5;241m.\u001B[39menviron\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mSERPAPI_API_KEY\u001B[39m\u001B[38;5;124m'\u001B[39m)}\n\u001B[1;32m---> 11\u001B[0m search \u001B[38;5;241m=\u001B[39m \u001B[43mGoogleSearch\u001B[49m(params)\n\u001B[0;32m     12\u001B[0m response \u001B[38;5;241m=\u001B[39m search\u001B[38;5;241m.\u001B[39mget_dict()\n\u001B[0;32m     14\u001B[0m knowledge_graph \u001B[38;5;241m=\u001B[39m response\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mknowledge_graph\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m)\n",
      "\u001B[1;31mNameError\u001B[0m: name 'GoogleSearch' is not defined"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# retrieval and vdb creation"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-14T02:35:46.290672Z",
     "start_time": "2024-09-14T02:35:34.589541Z"
    }
   },
   "source": [
    "from utils.vectordb.vector_db import VectorDb\n",
    "\n",
    "vectordb = VectorDb()\n",
    "config = {'persist_directory': 'NoneDirectory'}\n",
    "documents = docs\n",
    "\n",
    "def create_and_save_local(input_directory=None, persist_directory=None, update=False):\n",
    "    *_, retrieval_info, _, _ = get_config_info()\n",
    "    persist_directory = config.get('persist_directory', 'NoneDirectory')\n",
    "\n",
    "    chunks = vectordb.get_text_chunks(documents, retrieval_info['chunk_size'], retrieval_info['chunk_overlap'])\n",
    "    encode_kwargs = {\"normalize_embeddings\": True}\n",
    "    embeddings = HuggingFaceInstructEmbeddings(\n",
    "        model_name=\"BAAI/bge-large-en\",\n",
    "        embed_instruction=\"\",  # no instruction is needed for candidate passages\n",
    "        query_instruction=\"Represent this paragraph for searching relevant passages: \",\n",
    "        encode_kwargs=encode_kwargs,\n",
    "    )\n",
    "    if update and os.path.exists(persist_directory):\n",
    "        config['update'] = True\n",
    "        vector_store = vectordb.update_vdb(\n",
    "            chunks, embeddings, retrieval_info['db_type'], input_directory, persist_directory\n",
    "        )\n",
    "\n",
    "    else:\n",
    "        if os.path.exists(persist_directory):\n",
    "            vector_store = vectordb.create_vector_store(\n",
    "                chunks, embeddings, retrieval_info['db_type'], persist_directory\n",
    "            )\n",
    "        else:\n",
    "            vector_store = vectordb.create_vector_store(chunks, embeddings, retrieval_info['db_type'], None)\n",
    "    \n",
    "    return vector_store\n",
    "\n",
    "\n",
    "vector_store = create_and_save_local()"
   ],
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'docs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[19], line 5\u001B[0m\n\u001B[0;32m      3\u001B[0m vectordb \u001B[38;5;241m=\u001B[39m VectorDb()\n\u001B[0;32m      4\u001B[0m config \u001B[38;5;241m=\u001B[39m {\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mpersist_directory\u001B[39m\u001B[38;5;124m'\u001B[39m: \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mNoneDirectory\u001B[39m\u001B[38;5;124m'\u001B[39m}\n\u001B[1;32m----> 5\u001B[0m documents \u001B[38;5;241m=\u001B[39m \u001B[43mdocs\u001B[49m\n\u001B[0;32m      7\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mcreate_and_save_local\u001B[39m(input_directory\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, persist_directory\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, update\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m):\n\u001B[0;32m      8\u001B[0m     \u001B[38;5;241m*\u001B[39m_, retrieval_info, _, _ \u001B[38;5;241m=\u001B[39m get_config_info()\n",
      "\u001B[1;31mNameError\u001B[0m: name 'docs' is not defined"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-14T02:36:13.892038Z",
     "start_time": "2024-09-14T02:36:13.429291Z"
    }
   },
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "\n",
    "def retrieval_qa_chain():\n",
    "    *_, retrieval_info, _, _ = get_config_info()\n",
    "    prompt = load_prompt(os.path.join(kit_dir, 'prompts/llama3-web_scraped_data_retriever.yaml'))\n",
    "    retriever = vector_store.as_retriever(\n",
    "        search_type='similarity_score_threshold',\n",
    "        search_kwargs={\n",
    "            'score_threshold': retrieval_info['score_treshold'],\n",
    "            'k': retrieval_info['k_retrieved_documents'],\n",
    "        },\n",
    "    )\n",
    "    qa_chain = RetrievalQA.from_llm(\n",
    "        llm=llm,\n",
    "        retriever=retriever,\n",
    "        return_source_documents=True,\n",
    "        verbose=True,\n",
    "        input_key='question',\n",
    "        output_key='answer',\n",
    "        prompt=prompt,\n",
    "    )\n",
    "    return qa_chain"
   ],
   "outputs": [],
   "execution_count": 21
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-14T02:36:15.938090Z",
     "start_time": "2024-09-14T02:36:15.801848Z"
    }
   },
   "source": [
    "chain = retrieval_qa_chain()"
   ],
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'CONFIG_PATH' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[22], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m chain \u001B[38;5;241m=\u001B[39m \u001B[43mretrieval_qa_chain\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[1;32mIn[21], line 5\u001B[0m, in \u001B[0;36mretrieval_qa_chain\u001B[1;34m()\u001B[0m\n\u001B[0;32m      4\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mretrieval_qa_chain\u001B[39m():\n\u001B[1;32m----> 5\u001B[0m     \u001B[38;5;241m*\u001B[39m_, retrieval_info, _, _ \u001B[38;5;241m=\u001B[39m \u001B[43mget_config_info\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      6\u001B[0m     prompt \u001B[38;5;241m=\u001B[39m load_prompt(os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mjoin(kit_dir, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mprompts/llama3-web_scraped_data_retriever.yaml\u001B[39m\u001B[38;5;124m'\u001B[39m))\n\u001B[0;32m      7\u001B[0m     retriever \u001B[38;5;241m=\u001B[39m vector_store\u001B[38;5;241m.\u001B[39mas_retriever(\n\u001B[0;32m      8\u001B[0m         search_type\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124msimilarity_score_threshold\u001B[39m\u001B[38;5;124m'\u001B[39m,\n\u001B[0;32m      9\u001B[0m         search_kwargs\u001B[38;5;241m=\u001B[39m{\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m     12\u001B[0m         },\n\u001B[0;32m     13\u001B[0m     )\n",
      "Cell \u001B[1;32mIn[12], line 6\u001B[0m, in \u001B[0;36mget_config_info\u001B[1;34m()\u001B[0m\n\u001B[0;32m      2\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m      3\u001B[0m \u001B[38;5;124;03mLoads json config file\u001B[39;00m\n\u001B[0;32m      4\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m      5\u001B[0m \u001B[38;5;66;03m# Read config file\u001B[39;00m\n\u001B[1;32m----> 6\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mopen\u001B[39m(\u001B[43mCONFIG_PATH\u001B[49m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mr\u001B[39m\u001B[38;5;124m'\u001B[39m) \u001B[38;5;28;01mas\u001B[39;00m yaml_file:\n\u001B[0;32m      7\u001B[0m     config \u001B[38;5;241m=\u001B[39m yaml\u001B[38;5;241m.\u001B[39msafe_load(yaml_file)\n\u001B[0;32m      8\u001B[0m api_info \u001B[38;5;241m=\u001B[39m config[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mapi\u001B[39m\u001B[38;5;124m'\u001B[39m]\n",
      "\u001B[1;31mNameError\u001B[0m: name 'CONFIG_PATH' is not defined"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-14T02:36:16.944132Z",
     "start_time": "2024-09-14T02:36:16.905926Z"
    }
   },
   "source": "chain.invoke('who is joe biden')",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'chain' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[23], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[43mchain\u001B[49m\u001B[38;5;241m.\u001B[39minvoke(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mwho is joe biden\u001B[39m\u001B[38;5;124m'\u001B[39m))\n",
      "\u001B[1;31mNameError\u001B[0m: name 'chain' is not defined"
     ]
    }
   ],
   "execution_count": 23
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gsaenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
